{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Furiosa Artifacts This repository provides deep learning models provided by FuriosaAI. Available models are described in artifacts.py which is a descriptor file in the form defined by furiosa-registry Installation Load models via furiosa-models . pip install furiosa-models Example import asyncio from furiosa.registry import Model from furiosa.models.vision import MLCommonsResNet50 model : Model = asyncio . run ( MLCommonsResNet50 ()) License Copyright (c) 2021 FuriosaAI Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Overview"},{"location":"#furiosa-artifacts","text":"This repository provides deep learning models provided by FuriosaAI. Available models are described in artifacts.py which is a descriptor file in the form defined by furiosa-registry","title":"Furiosa Artifacts"},{"location":"#installation","text":"Load models via furiosa-models . pip install furiosa-models","title":"Installation"},{"location":"#example","text":"import asyncio from furiosa.registry import Model from furiosa.models.vision import MLCommonsResNet50 model : Model = asyncio . run ( MLCommonsResNet50 ())","title":"Example"},{"location":"#license","text":"Copyright (c) 2021 FuriosaAI Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"changelog/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on keep a changelog . [0.0.1]","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on keep a changelog .","title":"Changelog"},{"location":"changelog/#001","text":"","title":"[0.0.1]"},{"location":"models/","text":"Available models List Image Classification ResNet50-v1.5 EfficientNetV2_S EfficientNetV2_M Object detection SSD-ResNet34 SSD-MobileNets-v1 Details artifacts.py import io from typing import Any import aiohttp import dvc.api from furiosa.registry import Format , Metadata , Model , Publication from furiosa.artifacts.vision.models.image_classification import ( EfficientNetV2_M as EfficientNetV2_MModel , ) from furiosa.artifacts.vision.models.image_classification import ( EfficientNetV2_S as EfficientNetV2_SModel , ) from furiosa.artifacts.vision.models.image_classification import MLCommonsResNet50Model from furiosa.artifacts.vision.models.object_detection import ( MLCommonsSSDLargeModel , MLCommonsSSDSmallModel , ) async def load_dvc ( uri : str ): async with aiohttp . ClientSession () as session : async with session . get ( dvc . api . get_url ( uri )) as resp : return await resp . read () # Image classification async def MLCommonsResNet50 ( * args : Any , ** kwargs : Any ) -> MLCommonsResNet50Model : return MLCommonsResNet50Model ( name = \"MLCommonsResNet50\" , model = await load_dvc ( \"models/mlcommons_resnet50_v1.5_int8.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.5\" , metadata = Metadata ( description = \"ResNet50 v1.5 int8 ImageNet-1K Accuracy 75.982% @ Top1\" , publication = Publication ( url = \"https://arxiv.org/abs/1512.03385.pdf\" ), ), * args , ** kwargs , ) async def EfficientNetV2_S ( * args : Any , ** kwargs : Any ) -> Model : return Model ( name = \"EfficientNetV2_S\" , model = EfficientNetV2_SModel () . export ( io . BytesIO ()) . getvalue (), format = Format . ONNX , family = \"EfficientNet\" , version = \"v2.0\" , metadata = Metadata ( description = \"EfficientNetV2 from Google AutoML\" , publication = Publication ( url = \"https://arxiv.org/abs/2104.00298\" ), ), * args , ** kwargs , ) async def EfficientNetV2_M ( * args : Any , ** kwargs : Any ) -> Model : return Model ( name = \"EfficientNetV2_M\" , model = EfficientNetV2_MModel () . export ( io . BytesIO ()) . getvalue (), format = Format . ONNX , family = \"EfficientNet\" , version = \"v2.0\" , metadata = Metadata ( description = \"EfficientNetV2 from Google AutoML\" , publication = Publication ( url = \"https://arxiv.org/abs/2104.00298\" ), ), * args , ** kwargs , ) # Object detection async def MLCommonsSSDMobileNet ( * args : Any , ** kwargs : Any ) -> MLCommonsSSDSmallModel : return MLCommonsSSDSmallModel ( name = \"MLCommonsSSDMobileNet\" , model = await load_dvc ( \"models/mlcommons_ssd_mobilenet_v1_int8.onnx\" ), format = Format . ONNX , family = \"MobileNetV1\" , version = \"v1.1\" , metadata = Metadata ( description = \"MobileNet v1 model for MLCommons v1.1\" , publication = Publication ( url = \"https://arxiv.org/abs/1704.04861.pdf\" ), ), * args , ** kwargs , ) async def MLCommonsSSDResNet34 ( * args : Any , ** kwargs : Any ) -> MLCommonsSSDLargeModel : return MLCommonsSSDLargeModel ( name = \"MLCommonsSSDResNet34\" , model = await load_dvc ( \"models/mlcommons_ssd_resnet34_int8.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.1\" , metadata = Metadata ( description = \"ResNet34 model for MLCommons v1.1\" , publication = Publication ( url = \"https://github.com/mlcommons/inference/tree/master/vision/classification_and_detection\" # noqa: E501 ), ), * args , ** kwargs , )","title":"Available models"},{"location":"models/#available-models","text":"","title":"Available models"},{"location":"models/#list","text":"","title":"List"},{"location":"models/#image-classification","text":"ResNet50-v1.5 EfficientNetV2_S EfficientNetV2_M","title":"Image Classification"},{"location":"models/#object-detection","text":"SSD-ResNet34 SSD-MobileNets-v1","title":"Object detection"},{"location":"models/#details","text":"artifacts.py import io from typing import Any import aiohttp import dvc.api from furiosa.registry import Format , Metadata , Model , Publication from furiosa.artifacts.vision.models.image_classification import ( EfficientNetV2_M as EfficientNetV2_MModel , ) from furiosa.artifacts.vision.models.image_classification import ( EfficientNetV2_S as EfficientNetV2_SModel , ) from furiosa.artifacts.vision.models.image_classification import MLCommonsResNet50Model from furiosa.artifacts.vision.models.object_detection import ( MLCommonsSSDLargeModel , MLCommonsSSDSmallModel , ) async def load_dvc ( uri : str ): async with aiohttp . ClientSession () as session : async with session . get ( dvc . api . get_url ( uri )) as resp : return await resp . read () # Image classification async def MLCommonsResNet50 ( * args : Any , ** kwargs : Any ) -> MLCommonsResNet50Model : return MLCommonsResNet50Model ( name = \"MLCommonsResNet50\" , model = await load_dvc ( \"models/mlcommons_resnet50_v1.5_int8.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.5\" , metadata = Metadata ( description = \"ResNet50 v1.5 int8 ImageNet-1K Accuracy 75.982% @ Top1\" , publication = Publication ( url = \"https://arxiv.org/abs/1512.03385.pdf\" ), ), * args , ** kwargs , ) async def EfficientNetV2_S ( * args : Any , ** kwargs : Any ) -> Model : return Model ( name = \"EfficientNetV2_S\" , model = EfficientNetV2_SModel () . export ( io . BytesIO ()) . getvalue (), format = Format . ONNX , family = \"EfficientNet\" , version = \"v2.0\" , metadata = Metadata ( description = \"EfficientNetV2 from Google AutoML\" , publication = Publication ( url = \"https://arxiv.org/abs/2104.00298\" ), ), * args , ** kwargs , ) async def EfficientNetV2_M ( * args : Any , ** kwargs : Any ) -> Model : return Model ( name = \"EfficientNetV2_M\" , model = EfficientNetV2_MModel () . export ( io . BytesIO ()) . getvalue (), format = Format . ONNX , family = \"EfficientNet\" , version = \"v2.0\" , metadata = Metadata ( description = \"EfficientNetV2 from Google AutoML\" , publication = Publication ( url = \"https://arxiv.org/abs/2104.00298\" ), ), * args , ** kwargs , ) # Object detection async def MLCommonsSSDMobileNet ( * args : Any , ** kwargs : Any ) -> MLCommonsSSDSmallModel : return MLCommonsSSDSmallModel ( name = \"MLCommonsSSDMobileNet\" , model = await load_dvc ( \"models/mlcommons_ssd_mobilenet_v1_int8.onnx\" ), format = Format . ONNX , family = \"MobileNetV1\" , version = \"v1.1\" , metadata = Metadata ( description = \"MobileNet v1 model for MLCommons v1.1\" , publication = Publication ( url = \"https://arxiv.org/abs/1704.04861.pdf\" ), ), * args , ** kwargs , ) async def MLCommonsSSDResNet34 ( * args : Any , ** kwargs : Any ) -> MLCommonsSSDLargeModel : return MLCommonsSSDLargeModel ( name = \"MLCommonsSSDResNet34\" , model = await load_dvc ( \"models/mlcommons_ssd_resnet34_int8.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.1\" , metadata = Metadata ( description = \"ResNet34 model for MLCommons v1.1\" , publication = Publication ( url = \"https://github.com/mlcommons/inference/tree/master/vision/classification_and_detection\" # noqa: E501 ), ), * args , ** kwargs , )","title":"Details"},{"location":"models/efficientnet_v2_m/","text":"EfficientNet v2 M","title":"EfficientNet v2 M"},{"location":"models/efficientnet_v2_m/#efficientnet-v2-m","text":"","title":"EfficientNet v2 M"},{"location":"models/efficientnet_v2_s/","text":"EfficientNet v2 S","title":"EfficientNet v2 S"},{"location":"models/efficientnet_v2_s/#efficientnet-v2-s","text":"","title":"EfficientNet v2 S"},{"location":"models/resnet50_v1.5/","text":"ResNet50 v1.5","title":"ResNet50 v1.5"},{"location":"models/resnet50_v1.5/#resnet50-v15","text":"","title":"ResNet50 v1.5"},{"location":"models/ssd_mobilenet_v1/","text":"SSD MobileNet v1","title":"SSD MobileNet v1"},{"location":"models/ssd_mobilenet_v1/#ssd-mobilenet-v1","text":"","title":"SSD MobileNet v1"},{"location":"models/ssd_resnet34/","text":"SSD ResNet34","title":"SSD ResNet34"},{"location":"models/ssd_resnet34/#ssd-resnet34","text":"","title":"SSD ResNet34"},{"location":"usage/loading/","text":"Loading models You can load models provided by Furiosa Artifacts using furiosa-models which based on furiosa-registry . Example import asyncio from furiosa.models.vision import ResNet18 from furiosa.registry import Model model : Model = asyncio . run ( ResNet18 ( pretrained = True )) print ( model . name ) print ( model . format ) print ( model . metadata . description ) What's going on here: ResNet18(pretrained=True) Create model instance. This function ultimately calls the function entrypoint which provided by artifacts.py in furiosa-artifacts pretrained=True is an arbitrary argument which will transparently pass to model init. You can see what arguments are defined in the model class. asyncio.run() Function entrypoints provided by Furiosa Artifacts are async by default to support concurrency to load models. You need to call the entrypoints in async functions or async eventloop.","title":"Loading models"},{"location":"usage/loading/#loading-models","text":"You can load models provided by Furiosa Artifacts using furiosa-models which based on furiosa-registry .","title":"Loading models"},{"location":"usage/loading/#example","text":"import asyncio from furiosa.models.vision import ResNet18 from furiosa.registry import Model model : Model = asyncio . run ( ResNet18 ( pretrained = True )) print ( model . name ) print ( model . format ) print ( model . metadata . description ) What's going on here: ResNet18(pretrained=True) Create model instance. This function ultimately calls the function entrypoint which provided by artifacts.py in furiosa-artifacts pretrained=True is an arbitrary argument which will transparently pass to model init. You can see what arguments are defined in the model class. asyncio.run() Function entrypoints provided by Furiosa Artifacts are async by default to support concurrency to load models. You need to call the entrypoints in async functions or async eventloop.","title":"Example"},{"location":"usage/publishing/","text":"Publishing models Furiosa Artifacts use model class in furiosa-registry to publish models. furiosa-registry will find available models via a descriptor file named artifacts.py . To publish models, as a model provider you need to add function entrypoints which returns a model instance in artifacts.py Since github is not suitable for storing large data files, please use DVC for such purpose. A detailed description can be found on this section Example artifacts.py from typing import Any from furiosa.registry import Format , Metadata , Model , Publication from furiosa.registry.client.transport import FileTransport loader = FileTransport () class ResNet18_Model ( Model ): \"\"\" # This docstring shows up in furisao.registry.help() ResNet 18 model # Additional arguments pretrained (bool): kwargs, load pretrained weights into th model \"\"\" def __init__ ( self , pretrained : bool ): ... def preprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... def postprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... async def ResNet18 ( * args : Any , ** kwargs : Any ) -> ResNet18_Model : return ResNet18_Model ( name = \"ResNet18\" , model = await loader . read ( \"models/resnet18.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.0\" , metadata = Metadata ( description = \"Model description\" , publication = Publication ( url = \"Model publication URL\" ), ), ** kwargs , ) What's going on here: class ResNet18_Model(Model) Model class implements furiosa.registry.Model . furiosa.registry.Model is a class which you have to implement to publish your model. This model class is based on a pydantic Model and have several required fields to fill including: name model name. model model binary bytes. format model binary format. \"onnx\" or \"tflite\" are supported. def preprocess(self, *args: Any, **kwargs: Any) -> Any def postprocess(self, *args: Any, **kwargs: Any) -> Any Additional functions to suppport model modification. As a model provider, you can add pre-process, post-process functions to provide model specific functionalities. Note that this custom functions are not defined via interface which means you can add any custom functions. As users does not know which functions are provided, you have to document these functions to allow clients to use models correctly. async def ResNet18(*args: Any, **kwargs: Any) -> ResNet18_Model Function entrypoint which will be called from furiosa-registry . model=await loader.read(\"models/resnet18.onnx\") Loading model binary bytes via furiosa.registry.client.transport . You may use different ways to load binary bytes depending on how you maintain your model binary. How to use DVC for Furiosa Artifacts DVC Model binary files(e.g. *.onnx , *.tflite ) are usually too large for github to process. Therefore we handle these files with DVC , a version control system specialized for handling ML models and data sets. DVC installation You can install dvc by following this instruction . You probably need dvc[s3] python package since this repository uses s3 as DVC's backend. DVC pipeline Download model files via DVC # ` origin ` is specified in [ .dvc/config ]( .dvc/config ) , # -j option specifies num of parallel downloads $ dvc pull -r origin -j 10 Add a new data via DVC # ` origin ` is specified in [ .dvc/config ]( .dvc/config ) , # -j option specifies num of parallel downloads $ touch ./models/example-model $ dvc add -R ./models/example-model $ dvc push -r origin # Please follow DVC ' s instructions to follow these changes with git","title":"Publishing models"},{"location":"usage/publishing/#publishing-models","text":"Furiosa Artifacts use model class in furiosa-registry to publish models. furiosa-registry will find available models via a descriptor file named artifacts.py . To publish models, as a model provider you need to add function entrypoints which returns a model instance in artifacts.py Since github is not suitable for storing large data files, please use DVC for such purpose. A detailed description can be found on this section","title":"Publishing models"},{"location":"usage/publishing/#example","text":"artifacts.py from typing import Any from furiosa.registry import Format , Metadata , Model , Publication from furiosa.registry.client.transport import FileTransport loader = FileTransport () class ResNet18_Model ( Model ): \"\"\" # This docstring shows up in furisao.registry.help() ResNet 18 model # Additional arguments pretrained (bool): kwargs, load pretrained weights into th model \"\"\" def __init__ ( self , pretrained : bool ): ... def preprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... def postprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... async def ResNet18 ( * args : Any , ** kwargs : Any ) -> ResNet18_Model : return ResNet18_Model ( name = \"ResNet18\" , model = await loader . read ( \"models/resnet18.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.0\" , metadata = Metadata ( description = \"Model description\" , publication = Publication ( url = \"Model publication URL\" ), ), ** kwargs , ) What's going on here: class ResNet18_Model(Model) Model class implements furiosa.registry.Model . furiosa.registry.Model is a class which you have to implement to publish your model. This model class is based on a pydantic Model and have several required fields to fill including: name model name. model model binary bytes. format model binary format. \"onnx\" or \"tflite\" are supported. def preprocess(self, *args: Any, **kwargs: Any) -> Any def postprocess(self, *args: Any, **kwargs: Any) -> Any Additional functions to suppport model modification. As a model provider, you can add pre-process, post-process functions to provide model specific functionalities. Note that this custom functions are not defined via interface which means you can add any custom functions. As users does not know which functions are provided, you have to document these functions to allow clients to use models correctly. async def ResNet18(*args: Any, **kwargs: Any) -> ResNet18_Model Function entrypoint which will be called from furiosa-registry . model=await loader.read(\"models/resnet18.onnx\") Loading model binary bytes via furiosa.registry.client.transport . You may use different ways to load binary bytes depending on how you maintain your model binary.","title":"Example"},{"location":"usage/publishing/#how-to-use-dvc-for-furiosa-artifacts","text":"","title":"How to use DVC for Furiosa Artifacts"},{"location":"usage/publishing/#dvc","text":"Model binary files(e.g. *.onnx , *.tflite ) are usually too large for github to process. Therefore we handle these files with DVC , a version control system specialized for handling ML models and data sets.","title":"DVC"},{"location":"usage/publishing/#dvc-installation","text":"You can install dvc by following this instruction . You probably need dvc[s3] python package since this repository uses s3 as DVC's backend.","title":"DVC installation"},{"location":"usage/publishing/#dvc-pipeline","text":"Download model files via DVC # ` origin ` is specified in [ .dvc/config ]( .dvc/config ) , # -j option specifies num of parallel downloads $ dvc pull -r origin -j 10 Add a new data via DVC # ` origin ` is specified in [ .dvc/config ]( .dvc/config ) , # -j option specifies num of parallel downloads $ touch ./models/example-model $ dvc add -R ./models/example-model $ dvc push -r origin # Please follow DVC ' s instructions to follow these changes with git","title":"DVC pipeline"},{"location":"usage/running/","text":"Running models You can run inference via models provided by Furiosa Artifacts using furiosa-runtime . Example import asyncio from furiosa.models.vision import ResNet18 from furiosa.registry import Model from furiosa.runtime import session model : Model = asyncio . run ( ResNet18 ()) with session . create ( model . model ) as session : # Load input data data = ... # Pre-process the input data via provided preprocess function by furiosa-artifacts input = model . preprocess ( data ) output = session . run ( input ) # Post-process the output data via provided preprocess function by furiosa-artifacts model . postprocess ( output ) with session.create(model.model) as session: Session in furiosa-runtime needs model binary when creating the session. As models provided by furiosa-models have model field which is bytes formatted model binary, you can pass the model into the session. input = model.preprocess(data) output = model.postprocess(output) Model pre/post processing via the functions provided by Furiosa Artifacts. There may be other functions in Model class provided by model providers. As a model client, you should find the documents to find which functions are available. output = session.run(input) Run inference via the session. More references You can find Furiosa runtime API references and examples in SDK documentation","title":"Running models"},{"location":"usage/running/#running-models","text":"You can run inference via models provided by Furiosa Artifacts using furiosa-runtime .","title":"Running models"},{"location":"usage/running/#example","text":"import asyncio from furiosa.models.vision import ResNet18 from furiosa.registry import Model from furiosa.runtime import session model : Model = asyncio . run ( ResNet18 ()) with session . create ( model . model ) as session : # Load input data data = ... # Pre-process the input data via provided preprocess function by furiosa-artifacts input = model . preprocess ( data ) output = session . run ( input ) # Post-process the output data via provided preprocess function by furiosa-artifacts model . postprocess ( output ) with session.create(model.model) as session: Session in furiosa-runtime needs model binary when creating the session. As models provided by furiosa-models have model field which is bytes formatted model binary, you can pass the model into the session. input = model.preprocess(data) output = model.postprocess(output) Model pre/post processing via the functions provided by Furiosa Artifacts. There may be other functions in Model class provided by model providers. As a model client, you should find the documents to find which functions are available. output = session.run(input) Run inference via the session.","title":"Example"},{"location":"usage/running/#more-references","text":"You can find Furiosa runtime API references and examples in SDK documentation","title":"More references"}]}